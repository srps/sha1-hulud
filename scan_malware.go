// scan_malware.go
package main

import (
	"encoding/csv"
	"encoding/json"
	"flag"
	"fmt"
	"io"
	"io/fs"
	"net/http"
	"os"
	"os/exec"
	"path/filepath"
	"runtime"
	"strings"
	"sync"
	"time"

	"github.com/charlievieth/fastwalk"
)

func main() {
	csvPath := flag.String("csv", "", "path to CSV file with package names and versions (or use -download to fetch latest)")
	root := flag.String("root", "", "file system root to scan for node_modules (default: user home)")
	download := flag.Bool("download", false, "download latest IOCs from Wiz Research GitHub")
	flag.Parse()

	var finalCSVPath string
	var err error

	if *download {
		fmt.Println("ðŸ“¥ Downloading latest Shai-Hulud IOCs from Wiz Research...")
		finalCSVPath, err = downloadWizIOCs()
		if err != nil {
			fmt.Printf("Error downloading IOCs: %v\n", err)
			fmt.Println("Falling back to local CSV if provided...")
			if *csvPath == "" {
				fmt.Println("Please specify -csv /path/to/file.csv or ensure -download can access the internet")
				os.Exit(1)
			}
			finalCSVPath = *csvPath
		} else {
			fmt.Printf("âœ… Downloaded IOCs to: %s\n", finalCSVPath)
		}
	} else {
		if *csvPath == "" {
			fmt.Println("Please specify -csv /path/to/file.csv or use -download to fetch latest")
			fmt.Println("CSV format: Package,Version (supports Wiz format with '= ' prefix and '||' separators)")
			os.Exit(1)
		}
		finalCSVPath = *csvPath
	}

	packageVersions, err := readCSVPackageVersions(finalCSVPath)
	if err != nil {
		fmt.Printf("Error reading CSV: %v\n", err)
		os.Exit(1)
	}

	fmt.Printf("ðŸ“‹ Loaded %d compromised package versions\n", len(packageVersions))

	scanRoot := *root
	if scanRoot == "" {
		scanRoot = os.Getenv("HOME")
		if scanRoot == "" {
			scanRoot = "/"
		}
	}

	fmt.Println("ðŸ” Scanning for sha1-hulud malicious packages...")
	fmt.Println("Scanning under:", scanRoot)
	nmDirs := findNodeModulesDirs(scanRoot)
	fmt.Printf("Found %d node_modules directories\n", len(nmDirs))

	if len(nmDirs) > 0 {
		numWorkers := runtime.NumCPU()
		if numWorkers > len(nmDirs) {
			numWorkers = len(nmDirs)
		}
		fmt.Printf("Using %d parallel workers\n", numWorkers)
	}

	// Parallel scanning with goroutines
	foundCompromised, attackIndicators := scanNodeModulesParallel(nmDirs, packageVersions)

	// Scan global packages (npm, pnpm) and Bun cache
	fmt.Println("\nðŸ” Scanning global packages and Bun cache...")
	globalCompromised, globalIndicators := scanGlobalPackagesAndCache(packageVersions)
	for pv, locs := range globalCompromised {
		foundCompromised[pv] = append(foundCompromised[pv], locs...)
	}
	attackIndicators = append(attackIndicators, globalIndicators...)

	// Scan for GitHub workflow files (Shai-Hulud creates malicious workflows)
	fmt.Println("\nðŸ” Scanning for malicious GitHub workflows...")
	workflowIndicators := scanGitHubWorkflows(scanRoot)
	if len(workflowIndicators) > 0 {
		fmt.Printf("Found %d suspicious workflow files\n", len(workflowIndicators))
	}
	attackIndicators = append(attackIndicators, workflowIndicators...)

	// Report
	fmt.Println("\n" + strings.Repeat("=", 60))
	fmt.Println("SHA1-HULUD MALWARE SCAN REPORT")
	fmt.Println(strings.Repeat("=", 60))

	hasFindings := false

	if len(foundCompromised) > 0 {
		hasFindings = true
		fmt.Println("\nðŸ”´ COMPROMISED PACKAGES DETECTED:")
		for pv, locs := range foundCompromised {
			fmt.Printf("\n  Package: %s@%s\n", pv.Name, pv.Version)
			for _, loc := range locs {
				fmt.Printf("    â””â”€ %s\n", loc)
			}
		}
	}

	if len(attackIndicators) > 0 {
		hasFindings = true
		fmt.Println("\nâš ï¸  ATTACK INDICATORS FOUND:")
		for _, indicator := range attackIndicators {
			fmt.Printf("  â€¢ %s\n", indicator)
		}
	}

	if hasFindings {
		fmt.Println("\n" + strings.Repeat("=", 60))
		fmt.Println("ðŸš¨ IMMEDIATE ACTIONS REQUIRED:")
		fmt.Println(strings.Repeat("=", 60))
		fmt.Println("1. Rotate ALL credentials immediately:")
		fmt.Println("   - GitHub tokens & SSH keys")
		fmt.Println("   - npm tokens")
		fmt.Println("   - AWS, GCP, Azure credentials")
		fmt.Println("\n2. Check GitHub for malicious repos:")
		fmt.Println("   - Search for repos with 'Sha1-Hulud: The Second Coming'")
		fmt.Println("   - Delete any unauthorized repos")
		fmt.Println("\n3. Review GitHub Actions:")
		fmt.Println("   - Check .github/workflows/ for suspicious files")
		fmt.Println("   - Remove any unauthorized self-hosted runners")
		fmt.Println("\n4. Remove compromised packages:")
		fmt.Println("   - Delete and reinstall from clean versions")
		fmt.Println("   - Update to versions published before Nov 21, 2025")
		fmt.Println(strings.Repeat("=", 60))
		os.Exit(1)
	} else {
		fmt.Println("\nâœ… No sha1-hulud compromised packages detected")
		fmt.Println("\nðŸ’¡ Stay vigilant: New compromised packages may still be discovered.")
	}
}

// ========== CSV Reading ==========

// PackageVersion represents a package name and version combination
type PackageVersion struct {
	Name    string
	Version string
}

func readCSVPackageVersions(path string) (map[PackageVersion]struct{}, error) {
	f, err := os.Open(path)
	if err != nil {
		return nil, err
	}
	defer f.Close()

	reader := csv.NewReader(f)
	packages := make(map[PackageVersion]struct{})
	first := true
	for {
		record, err := reader.Read()
		if err == io.EOF {
			break
		}
		if err != nil {
			return nil, err
		}
		if first {
			first = false
			continue
		}
		if len(record) >= 2 {
			name := strings.TrimSpace(record[0])
			versionStr := strings.TrimSpace(record[1])

			if name == "" {
				continue
			}

			// Parse Wiz format: "= 0.0.7" or "= 0.0.7 || = 0.0.8" or empty
			versions := parseWizVersions(versionStr)

			if len(versions) == 0 {
				// Empty version - skip or add as wildcard? For now, skip
				continue
			}

			// Add each version as a separate entry
			for _, version := range versions {
				if version != "" {
					packages[PackageVersion{Name: name, Version: version}] = struct{}{}
				}
			}
		}
	}
	return packages, nil
}

// parseWizVersions parses Wiz format version strings:
// "= 0.0.7" -> ["0.0.7"]
// "= 0.0.7 || = 0.0.8" -> ["0.0.7", "0.0.8"]
// "" -> []
func parseWizVersions(versionStr string) []string {
	if versionStr == "" {
		return []string{}
	}

	// Split by " || " to handle multiple versions
	parts := strings.Split(versionStr, " || ")
	versions := make([]string, 0, len(parts))

	for _, part := range parts {
		part = strings.TrimSpace(part)
		// Remove "= " prefix if present
		if strings.HasPrefix(part, "= ") {
			part = strings.TrimPrefix(part, "= ")
			part = strings.TrimSpace(part)
		}
		if part != "" {
			versions = append(versions, part)
		}
	}

	return versions
}

// downloadWizIOCs downloads the latest IOCs CSV from Wiz Research GitHub
func downloadWizIOCs() (string, error) {
	url := "https://raw.githubusercontent.com/wiz-sec-public/wiz-research-iocs/main/reports/shai-hulud-2-packages.csv"

	client := &http.Client{
		Timeout: 30 * time.Second,
	}

	resp, err := client.Get(url)
	if err != nil {
		return "", fmt.Errorf("failed to download: %w", err)
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		return "", fmt.Errorf("unexpected status code: %d", resp.StatusCode)
	}

	// Create temp file
	tmpDir := os.TempDir()
	tmpFile := filepath.Join(tmpDir, fmt.Sprintf("shai-hulud-iocs-%d.csv", time.Now().Unix()))

	f, err := os.Create(tmpFile)
	if err != nil {
		return "", fmt.Errorf("failed to create temp file: %w", err)
	}
	defer f.Close()

	// Copy response body to file
	_, err = io.Copy(f, resp.Body)
	if err != nil {
		os.Remove(tmpFile) // Clean up on error
		return "", fmt.Errorf("failed to write file: %w", err)
	}

	return tmpFile, nil
}

// ========== Parallel Scanning ==========

// scanNodeModulesParallel scans multiple node_modules directories in parallel
func scanNodeModulesParallel(nmDirs []string, packageVersions map[PackageVersion]struct{}) (map[PackageVersion][]string, []string) {
	if len(nmDirs) == 0 {
		return make(map[PackageVersion][]string), []string{}
	}

	numWorkers := runtime.NumCPU()
	if numWorkers > len(nmDirs) {
		numWorkers = len(nmDirs)
	}

	// Semaphore to limit concurrent goroutines
	sem := make(chan struct{}, numWorkers)

	// Results collection with mutex for thread safety
	var mu sync.Mutex
	foundCompromised := make(map[PackageVersion][]string)
	attackIndicators := make([]string, 0)

	var wg sync.WaitGroup

	for _, dir := range nmDirs {
		wg.Add(1)
		go func(d string) {
			defer wg.Done()

			// Acquire semaphore
			sem <- struct{}{}
			defer func() { <-sem }() // Release semaphore

			// Scan directory
			compromised, indicators := scanNodeModulesDirForVersions(d, packageVersions)

			// Safely merge results
			mu.Lock()
			for pv, locs := range compromised {
				foundCompromised[pv] = append(foundCompromised[pv], locs...)
			}
			attackIndicators = append(attackIndicators, indicators...)
			mu.Unlock()
		}(dir)
	}

	wg.Wait()
	return foundCompromised, attackIndicators
}

// ========== node_modules Discovery ==========

func findNodeModulesDirs(root string) []string {
	var dirs []string
	var mu sync.Mutex

	// Use fastwalk for parallel directory traversal (~2.5x faster on macOS, ~4x faster on Linux)
	// The callback must be safe for concurrent use, so we use a mutex to protect the slice
	config := &fastwalk.Config{}
	err := fastwalk.Walk(config, root, func(path string, d fs.DirEntry, err error) error {
		// Handle errors (like permission denied) by skipping the problematic directory
		if err != nil {
			// Skip directories we can't access and continue walking
			return nil
		}

		if d.IsDir() && d.Name() == "node_modules" {
			mu.Lock()
			dirs = append(dirs, path)
			mu.Unlock()
			return filepath.SkipDir
		}
		return nil
	})

	if err != nil {
		// Log but don't fail - we may have found some directories before the error
		fmt.Printf("Warning: Some filesystem errors encountered: %v\n", err)
	}
	return dirs
}

func scanNodeModulesDirForVersions(dir string, packageVersions map[PackageVersion]struct{}) (map[PackageVersion][]string, []string) {
	found := make(map[PackageVersion][]string)
	indicators := make([]string, 0)

	entries, err := os.ReadDir(dir)
	if err != nil {
		return found, indicators
	}

	for _, e := range entries {
		if !e.IsDir() {
			continue
		}

		pkgName := e.Name()
		pkgPath := filepath.Join(dir, pkgName)

		// Handle scoped packages (@org/package)
		if strings.HasPrefix(pkgName, "@") {
			scopedEntries, err := os.ReadDir(pkgPath)
			if err != nil {
				continue
			}
			for _, scopedEntry := range scopedEntries {
				if !scopedEntry.IsDir() {
					continue
				}
				fullName := pkgName + "/" + scopedEntry.Name()
				scopedPath := filepath.Join(pkgPath, scopedEntry.Name())
				pv, inds := checkPackage(scopedPath, fullName, packageVersions)
				if pv != nil {
					found[*pv] = append(found[*pv], scopedPath)
				}
				indicators = append(indicators, inds...)
			}
		} else {
			pv, inds := checkPackage(pkgPath, pkgName, packageVersions)
			if pv != nil {
				found[*pv] = append(found[*pv], pkgPath)
			}
			indicators = append(indicators, inds...)
		}
	}

	return found, indicators
}

type PackageJSON struct {
	Name    string `json:"name"`
	Version string `json:"version"`
	Scripts struct {
		Preinstall  string `json:"preinstall"`
		Install     string `json:"install"`
		Postinstall string `json:"postinstall"`
	} `json:"scripts"`
}

func checkPackage(pkgPath, pkgName string, packageVersions map[PackageVersion]struct{}) (*PackageVersion, []string) {
	indicators := make([]string, 0)

	// Read package.json
	packageJSONPath := filepath.Join(pkgPath, "package.json")
	data, err := os.ReadFile(packageJSONPath)
	if err != nil {
		return nil, indicators
	}

	var pkg PackageJSON
	if err := json.Unmarshal(data, &pkg); err != nil {
		return nil, indicators
	}

	// Check if this exact package@version is compromised
	pv := PackageVersion{Name: pkgName, Version: pkg.Version}
	var foundPV *PackageVersion
	if _, exists := packageVersions[pv]; exists {
		foundPV = &pv
	}

	// Check for sha1-hulud attack indicators - payload files
	suspiciousFiles := []string{
		"setup_bun.js",
		"bun_environment.js",
		"actionsSecrets.json",
		"cloud.json",
		"contents.json",
		"environment.json",
		"truffleSecrets.json",
	}
	for _, file := range suspiciousFiles {
		filePath := filepath.Join(pkgPath, file)
		if _, err := os.Stat(filePath); err == nil {
			indicators = append(indicators, fmt.Sprintf("Suspicious file '%s' found in %s@%s at %s", file, pkgName, pkg.Version, pkgPath))
		}
	}

	// Check for suspicious preinstall scripts
	preinstall := strings.ToLower(pkg.Scripts.Preinstall)
	suspiciousPatterns := []string{
		"setup_bun",
		"bun.sh/install",
		"bun_environment",
		"cloud.json",
		"contents.json",
		"environment.json",
		"truffleSecrets",
	}
	for _, pattern := range suspiciousPatterns {
		if strings.Contains(preinstall, pattern) {
			indicators = append(indicators, fmt.Sprintf("Suspicious preinstall script pattern '%s' in %s@%s at %s", pattern, pkgName, pkg.Version, pkgPath))
			break
		}
	}

	return foundPV, indicators
}

// ========== Node Environment & Global Packages ==========

type NodeEnv struct {
	Manager string
	Version string
	BinDir  string
}

func (env NodeEnv) String() string {
	return fmt.Sprintf("%s@%s", env.Manager, env.Version)
}

func detectNodeEnvs() []NodeEnv {
	home := os.Getenv("HOME")
	envs := []NodeEnv{}

	// system node
	v, err := execOut("node", []string{"-v"})
	if err == nil {
		v = strings.TrimPrefix(v, "v")
		envs = append(envs, NodeEnv{"system", v, ""})
	}

	// nvm
	nvmDir := filepath.Join(home, ".nvm", "versions", "node")
	_ = filepath.WalkDir(nvmDir, func(p string, d fs.DirEntry, err error) error {
		if err != nil {
			return nil
		}
		if d.IsDir() && strings.HasPrefix(d.Name(), "v") {
			ver := strings.TrimPrefix(d.Name(), "v")
			bin := filepath.Join(p, "bin")
			envs = append(envs, NodeEnv{"nvm", ver, bin})
		}
		return nil
	})

	// fnm
	fnmDir := filepath.Join(home, ".fnm", "versions")
	_ = filepath.WalkDir(fnmDir, func(p string, d fs.DirEntry, err error) error {
		if err != nil {
			return nil
		}
		// version dirs are like "16.13.0"
		if d.IsDir() {
			envs = append(envs, NodeEnv{"fnm", d.Name(), filepath.Join(p, d.Name(), "bin")})
		}
		return nil
	})

	// asdf
	asdfDir := filepath.Join(home, ".asdf", "installs", "nodejs")
	_ = filepath.WalkDir(asdfDir, func(p string, d fs.DirEntry, err error) error {
		if err != nil {
			return nil
		}
		if d.IsDir() {
			envs = append(envs, NodeEnv{"asdf", d.Name(), filepath.Join(p, d.Name(), "bin")})
		}
		return nil
	})

	// mise
	miseBase := filepath.Join(home, ".local", "share", "mise", "installs", "node")
	if entries, err := os.ReadDir(miseBase); err == nil {
		for _, entry := range entries {
			// Only direct children of miseBase are versions (e.g., "24.11.1")
			if entry.IsDir() {
				version := entry.Name()
				binPath := filepath.Join(miseBase, version, "bin")
				// Verify bin directory exists to confirm it's a valid installation
				if _, err := os.Stat(binPath); err == nil {
					envs = append(envs, NodeEnv{"mise", version, binPath})
				}
			}
		}
	}

	return envs
}

func execOut(cmdName string, args []string) (string, error) {
	c := exec.Command(cmdName, args...)
	b, err := c.Output()
	if err != nil {
		return "", err
	}
	return string(b), nil
}

// scanGlobalPackagesAndCache scans global npm/pnpm packages and Bun cache
func scanGlobalPackagesAndCache(packageVersions map[PackageVersion]struct{}) (map[PackageVersion][]string, []string) {
	found := make(map[PackageVersion][]string)
	indicators := make([]string, 0)

	// Detect Node.js environments
	envs := detectNodeEnvs()
	if len(envs) > 0 {
		fmt.Printf("  Detected %d Node.js environment(s)\n", len(envs))
	}

	// Scan global packages for each environment
	for _, env := range envs {
		npmPackages, pnpmPackages := scanGlobalPackages(env)

		// Check npm global packages (map[string]string = name -> version)
		for pkgName, pkgVersion := range npmPackages {
			pv := PackageVersion{Name: pkgName, Version: pkgVersion}
			if _, exists := packageVersions[pv]; exists {
				location := fmt.Sprintf("npm global (%s)", env.String())
				found[pv] = append(found[pv], location)
			}
		}

		// Check pnpm global packages
		for pkgName, pkgVersion := range pnpmPackages {
			pv := PackageVersion{Name: pkgName, Version: pkgVersion}
			if _, exists := packageVersions[pv]; exists {
				location := fmt.Sprintf("pnpm global (%s)", env.String())
				found[pv] = append(found[pv], location)
			}
		}
	}

	// Scan Bun cache
	bunCacheCompromised, bunIndicators := scanBunCache(packageVersions)
	for pv, locs := range bunCacheCompromised {
		found[pv] = append(found[pv], locs...)
	}
	indicators = append(indicators, bunIndicators...)

	return found, indicators
}

func scanGlobalPackages(env NodeEnv) (map[string]string, map[string]string) {
	npmPackages := make(map[string]string) // name -> version
	pnpmPackages := make(map[string]string)

	var envPath []string
	if env.BinDir != "" {
		envPath = append([]string{env.BinDir}, strings.Split(os.Getenv("PATH"), string(os.PathListSeparator))...)
	} else {
		envPath = strings.Split(os.Getenv("PATH"), string(os.PathListSeparator))
	}

	osEnv := os.Environ()
	osEnv = append(osEnv, "PATH="+strings.Join(envPath, string(os.PathListSeparator)))

	// npm - extract name and version from JSON
	cmd := exec.Command("npm", "ls", "-g", "--depth=0", "--json")
	cmd.Env = osEnv
	out, err := cmd.CombinedOutput()
	if err == nil {
		var j map[string]interface{}
		if err := json.Unmarshal(out, &j); err == nil {
			deps, ok := j["dependencies"].(map[string]interface{})
			if ok {
				for pkgName, pkgInfo := range deps {
					if pkgMap, ok := pkgInfo.(map[string]interface{}); ok {
						if version, ok := pkgMap["version"].(string); ok {
							npmPackages[pkgName] = version
						}
					}
				}
			}
		}
	}

	// pnpm - extract name and version from JSON
	cmd2 := exec.Command("pnpm", "ls", "-g", "--depth=0", "--json")
	cmd2.Env = osEnv
	out2, err2 := cmd2.CombinedOutput()
	if err2 == nil {
		var j2 map[string]interface{}
		if err := json.Unmarshal(out2, &j2); err == nil {
			deps2, ok2 := j2["dependencies"].(map[string]interface{})
			if ok2 {
				for pkgName, pkgInfo := range deps2 {
					if pkgMap, ok := pkgInfo.(map[string]interface{}); ok {
						if version, ok := pkgMap["version"].(string); ok {
							pnpmPackages[pkgName] = version
						}
					}
				}
			}
		}
	}

	return npmPackages, pnpmPackages
}

// scanBunCache scans Bun's package cache for compromised packages
func scanBunCache(packageVersions map[PackageVersion]struct{}) (map[PackageVersion][]string, []string) {
	found := make(map[PackageVersion][]string)
	indicators := make([]string, 0)

	cacheDir := os.Getenv("BUN_INSTALL_CACHE_DIR")
	if cacheDir == "" {
		home := os.Getenv("HOME")
		if home == "" {
			return found, indicators
		}
		cacheDir = filepath.Join(home, ".bun", "install", "cache")
	}

	if _, err := os.Stat(cacheDir); os.IsNotExist(err) {
		return found, indicators
	}

	entries, err := os.ReadDir(cacheDir)
	if err != nil {
		return found, indicators
	}

	for _, entry := range entries {
		if !entry.IsDir() {
			continue
		}

		// Bun cache format: pkg@version
		nameVer := entry.Name()
		parts := strings.SplitN(nameVer, "@", 2)
		if len(parts) != 2 {
			continue
		}

		pkgName := parts[0]
		pkgVersion := parts[1]

		pv := PackageVersion{Name: pkgName, Version: pkgVersion}
		if _, exists := packageVersions[pv]; exists {
			cachePath := filepath.Join(cacheDir, nameVer)
			found[pv] = append(found[pv], fmt.Sprintf("Bun cache: %s", cachePath))
		}
	}

	return found, indicators
}

// ========== GitHub Workflow Scanning ==========

// scanGitHubWorkflows scans for malicious GitHub workflow files created by Shai-Hulud
func scanGitHubWorkflows(root string) []string {
	indicators := make([]string, 0)

	// Find all .github/workflows directories using fastwalk for better performance
	var workflowDirs []string
	var mu sync.Mutex

	config := &fastwalk.Config{}
	err := fastwalk.Walk(config, root, func(path string, d fs.DirEntry, err error) error {
		// Handle errors by skipping the problematic directory
		if err != nil {
			return nil
		}

		if d.IsDir() && d.Name() == ".github" {
			workflowsPath := filepath.Join(path, "workflows")
			if info, err := os.Stat(workflowsPath); err == nil && info.IsDir() {
				mu.Lock()
				workflowDirs = append(workflowDirs, workflowsPath)
				mu.Unlock()
			}
			return filepath.SkipDir
		}
		return nil
	})

	if err != nil {
		return indicators
	}

	for _, workflowDir := range workflowDirs {
		entries, err := os.ReadDir(workflowDir)
		if err != nil {
			continue
		}

		for _, entry := range entries {
			if entry.IsDir() {
				continue
			}

			fileName := entry.Name()
			filePath := filepath.Join(workflowDir, fileName)

			// Check for suspicious workflow files
			if fileName == "discussion.yaml" || fileName == "discussion.yml" {
				// Check if it contains the malicious pattern
				content, err := os.ReadFile(filePath)
				if err == nil {
					contentStr := string(content)
					if strings.Contains(contentStr, "self-hosted") &&
						(strings.Contains(contentStr, "github.event.discussion.body") ||
							strings.Contains(contentStr, "RUNNER_TRACKING_ID")) {
						indicators = append(indicators, fmt.Sprintf("Suspicious GitHub workflow file: %s (potential backdoor)", filePath))
					}
				}
			}

			// Check for formatter workflow files (Shai-Hulud creates formatter_*.yml files)
			if strings.HasPrefix(fileName, "formatter_") &&
				(strings.HasSuffix(fileName, ".yml") || strings.HasSuffix(fileName, ".yaml")) {
				content, err := os.ReadFile(filePath)
				if err == nil {
					contentStr := string(content)
					if strings.Contains(contentStr, "toJSON(secrets)") ||
						strings.Contains(contentStr, "actionsSecrets") {
						indicators = append(indicators, fmt.Sprintf("Suspicious GitHub workflow file: %s (potential secret exfiltration)", filePath))
					}
				}
			}
		}
	}

	return indicators
}
